{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5fd604-bb8b-4268-9ba3-23259cf10357",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbf845-8c72-4427-a155-22c7d0b34d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data  \n",
    "# in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using\n",
    "# online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that\n",
    "# allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or\n",
    "# they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1206e6-6103-4fbc-b4b6-fc7e5c3dd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping is commonly used to retrieve the most updated data about properties, sale prices, monthly rental income, amenities, property agents, and other data points. Web scraped \n",
    "# data also informs property value appraisals, rental yield estimates, and real estate market trends analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0006fb2-beec-45e7-adf8-340964be0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring e-commerce prices. Finding opportunities for investment. Analyzing social media web data. Applying machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a90a2-0213-4fd8-86f6-8616b04bd08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb1ab5-f6bf-4438-9c70-6c9dcd079d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "431b2f1b-25ea-4c42-bf30-1bb1d6ba4e20",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4c0ba-9b75-4614-a3b3-0bb52386602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 . HTML PARSING\n",
    "# 2. DOM PARSING\n",
    "# 3. VERTICAL AGGREGATION\n",
    "# 4. XPATH\n",
    "# 5 .GOOGLE SHEETS\n",
    "# 6. TEXT PATTERN MATCHING\n",
    "\n",
    "# and many more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e4dcf-4265-430e-a285-c89251c1dda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100df79-2804-4146-8bd2-14aacd47b29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efc3a8-678f-42a7-95ab-92c2dfffb987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b328f903-c40d-4512-a1e7-f931203dbcd6",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622d71f-f4d0-42e7-b663-33150ff0a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup is a Python library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser and provides Pythonic idioms for iterating, searching,\n",
    "# and modifying the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a402729-c5af-4b20-aa7b-04529c769acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Beautiful Soup library helps with isolating titles and links from webpages. It can extract all of the text from HTML tags, and alter the HTML in the document with which we’re\n",
    "# working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a02e3-1f67-4b0f-9ce6-99a13fa20039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1d4f9-e31e-4c55-93a4-84ccaeb9b806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ee2e5-c763-450a-862a-a2cb9cb867fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69d77ea0-d6e5-43f4-94c3-18c9760ba3c5",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a2ce9-7ae1-4a99-bc64-781d79e05c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http\n",
    "# requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22086e1a-d0c0-4afd-ad9b-9826ea89c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this project we used flask so that we can easily store our data into mongo db also in the easiest way and with the help of html and css to make it more convinient to use the \n",
    "# flipkart search box where we can search according to our need and after that we can also store it into github account in the very easiest way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ae715-f741-4de7-ad3f-29e95f40dbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9606b4-0e5f-44ed-847e-f6136ab016b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb696a0f-d5ef-4740-bf51-406c03224b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "055aaf7f-3c0e-49cc-98bd-385aec6df3f6",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ff433-a0ed-467b-911b-66580a0d2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Elastic Beanstalk\n",
    "2) CodePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5348e2-dda6-4c89-b25e-4b0251016c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Beanstalk \n",
    "\n",
    "# Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment—from capacity\n",
    "# provisioning, load balancing, and auto scaling to application health monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9c44e-8921-4f64-b19f-c2e829dec91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodePipeline \n",
    "\n",
    "# You can use CodePipeline to help you automatically build, test, and deploy your applications in the cloud. Specifically, you can: Automate your release processes: CodePipeline fully\n",
    "# automates your release process from end to end, starting from your source repository through build, test, and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11d4ef-7c2c-4d6d-9e19-b4b5331bf7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1dbf7e-faa9-4af3-8eea-64e8883c4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM\n",
    "\n",
    "# from the above all of this i also use IAM For creating Roles and give manage access to aws resources \n",
    "# AWS Identity and Access Management (IAM) is a web service that helps you securely control access to AWS resources. With IAM, you can centrally manage permissions that control which AWS\n",
    "# resources users can access. You use IAM to control who is authenticated (signed in) and authorized (has permissions) to use resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
